{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Proj 2 \n",
    "\n",
    "### Group Members: x, x, x ,x , Kevin Lee\n",
    "\n",
    "### Due: Nov 12th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "# 20newsgroups Data set\n",
    "twenty_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes')) # bunch object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17881"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 101631)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0).fit(X_train_tfidf, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43551237, 0.41696113, 0.44787986, 0.4319788 , 0.44916004,\n",
       "       0.4305924 , 0.46861185, 0.44650752, 0.45623342, 0.4535809 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "cross_val_score(text_clf,twenty_train.data, twenty_train.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ferna\\OneDrive\\Documents\\GitHub\\Mini-Project-2\\DecisonTree.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/OneDrive/Documents/GitHub/Mini-Project-2/DecisonTree.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m docs_test \u001b[39m=\u001b[39m twenty_test\u001b[39m.\u001b[39mdata\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ferna/OneDrive/Documents/GitHub/Mini-Project-2/DecisonTree.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicted \u001b[39m=\u001b[39m text_clf\u001b[39m.\u001b[39;49mpredict(docs_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/OneDrive/Documents/GitHub/Mini-Project-2/DecisonTree.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m np\u001b[39m.\u001b[39mmean(predicted \u001b[39m==\u001b[39m twenty_test\u001b[39m.\u001b[39mtarget)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    513\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 514\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1431\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(raw_documents, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterable over raw text documents expected, string object received.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1430\u001b[0m     )\n\u001b[1;32m-> 1431\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_vocabulary()\n\u001b[0;32m   1433\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:508\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 508\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mVocabulary not fitted or provided\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    511\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mVocabulary is empty\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
